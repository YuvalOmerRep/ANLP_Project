{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV4mwBCk-6rL"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install transformers==4.28.0\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoConfig , AutoTokenizer , AutoModelForMultipleChoice, TrainingArguments, Trainer, DefaultDataCollator\n",
        "from evaluate import load\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "accuracy = load(\"accuracy\")"
      ],
      "metadata": {
        "id": "ah1UM4xr_oA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "riddleSense_train = load_dataset('riddle_sense', split='train').shuffle()\n",
        "riddleSense_val = load_dataset('riddle_sense', split='validation')"
      ],
      "metadata": {
        "id": "9gGvDk36LTIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping_dict = {'A':0, 'B':1, \"C\":2, \"D\":3, \"E\":4}\n",
        "num_to_label_dict = {0:'A', 1:\"B\", 2:\"C\", 3:\"D\", 4:\"E\"}"
      ],
      "metadata": {
        "id": "4PVTZrVmTCP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess function, splits each sample into five samples where before we had a riddle and five possible answers, and now we have 5 samples each with the riddle and one of the answers."
      ],
      "metadata": {
        "id": "BYf-GwRD6K9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    question_headers = examples[\"question\"]\n",
        "    second_sentences = [\n",
        "        [f\"{header}[SEP]{examples['choices'][i]['text'][j]}\" for j in range(5)] for i, header in enumerate(question_headers)\n",
        "    ]\n",
        "\n",
        "    second_sentences = sum(second_sentences, [])\n",
        "\n",
        "    tokenized_examples = tokenizer(second_sentences, truncation=True)\n",
        "    return {k: [v[i : i + 5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}"
      ],
      "metadata": {
        "id": "lTyekOI5JY0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train = riddleSense_train.map(preprocess_function, batched=True)\n",
        "preprocessed_val = riddleSense_val.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "uXnIqrjWGeqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A costume DataCollator class for our praticular needs"
      ],
      "metadata": {
        "id": "m48fubgL6ihl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import torch\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = 'answerKey'\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "        num_choices = len(features[0][\"input_ids\"])\n",
        "        flattened_features = [\n",
        "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
        "        ]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "\n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
        "        new_labels = []\n",
        "        for label in labels:\n",
        "          new_labels.append(label_mapping_dict[label])\n",
        "        batch[\"labels\"] = torch.tensor(new_labels, dtype=torch.int64)\n",
        "        return batch"
      ],
      "metadata": {
        "id": "Fr5I_bY9OmKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\"riddle_sense_check\", save_strategy=\"no\", label_names=['answerKey'])"
      ],
      "metadata": {
        "id": "9Rd1qDvvKgPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  train_dataset=preprocessed_train,\n",
        "                  eval_dataset=preprocessed_val,\n",
        "                  tokenizer=tokenizer,\n",
        "                  compute_metrics=None,\n",
        "                  data_collator = DataCollatorForMultipleChoice(tokenizer))"
      ],
      "metadata": {
        "id": "FAAAH4oyK6ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "hm6yUv-fL8F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict on validation set and calculate accuracy"
      ],
      "metadata": {
        "id": "fKTkbr4c53Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(preprocessed_val)"
      ],
      "metadata": {
        "id": "Nn6dLCYiavaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping_func(n):\n",
        "  return label_mapping_dict[n]"
      ],
      "metadata": {
        "id": "u_TEspDzac36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(np.array(predictions.predictions[1]), axis=1)\n",
        "labels = np.array([i for i in map(mapping_func, preprocessed_val['answerKey'])])"
      ],
      "metadata": {
        "id": "nJoTKcxWZPYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(labels == preds).sum() / len(labels)"
      ],
      "metadata": {
        "id": "-dGGenR4axRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}